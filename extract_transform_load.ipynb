{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from psycopg2.extensions import register_adapter, AsIs\n",
    "psycopg2.extensions.register_adapter(np.int64, psycopg2._psycopg.AsIs)\n",
    "psycopg2.extensions.register_adapter(np.int32, psycopg2._psycopg.AsIs)\n",
    "# %run -i 'Create_Table_queries.py'\n",
    "from Create_Table_queries import *\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_youtubedata_file(cur, filepath): \n",
    "    \"\"\"\n",
    "        This function reads one JSON file and read information of videos and youtuber data and saves into video_data and youtuber_data\n",
    "        Arguments:\n",
    "        cur: Database Cursor\n",
    "        filepath: location of JSON files\n",
    "        Return: None\n",
    "    \"\"\"\n",
    "    # open JSON file\n",
    "    df = pd.read_json(filepath)\n",
    "\n",
    "    # ---------insert youtuber record----------\n",
    "    # write your code here that reads youtuber data from JSON file and insert it into Youtubers_dim table \n",
    "    \n",
    "\n",
    "    # write your code here\n",
    "    # I checked before that all json files have shape 1 * 10. so just assigning from 0th row\n",
    "    youtuber_record = (df.iloc[0][3],df.iloc[0][7],df.iloc[0][5],df.iloc[0][4],df.iloc[0][6])\n",
    "    cur.execute(Youtubers_table_insert, youtuber_record)\n",
    "\n",
    "    \n",
    "    # ---------insert video record--------------\n",
    "    # write your code here that reads youtube videos data from JSON file and insert it into Videos_dim table \n",
    "\n",
    "    # write your code here\n",
    "    year = df.iloc[0][2].astype(int)\n",
    "    video_record = (df.iloc[0][9],df.iloc[0][1],df.iloc[0][3],year,df.iloc[0][0])\n",
    "    cur.execute(Videos_table_insert, video_record)\n",
    "\n",
    "def convert_TS_to_date(ts):\n",
    "    dt_object = datetime.fromtimestamp(ts)\n",
    "    _date = dt_object.date()\n",
    "    _hr = dt_object.hour\n",
    "    _day = dt_object.day\n",
    "    _week_number = dt_object.isocalendar()[1]\n",
    "    _m = dt_object.month\n",
    "    _year = dt_object.year\n",
    "    _weekday= dt_object.weekday()\n",
    "    return _date,_hr,_day,_week_number,_m, _year, _weekday\n",
    "def get_startDate(ts):\n",
    "    dt_object = datetime.fromtimestamp(ts)\n",
    "    _date = dt_object.date()\n",
    "    return _date\n",
    "def get_UserData(df, i):\n",
    "    record = (df.loc[i]['userId'], df.loc[i]['firstName'], df.loc[i]['lastName'], df.loc[i]['gender'], df.loc[i]['level'])\n",
    "    return record\n",
    "\n",
    "def process_log_file(cur, filepath):\n",
    "    \"\"\"\n",
    "        This function reads Log files and reads information of time, user and videoplay data and saves into time, user, videoplay\n",
    "        Arguments:\n",
    "        cur: Database Cursor\n",
    "        filepath: location of Log files\n",
    "        Return: None\n",
    "    \"\"\"\n",
    "\n",
    "    # open log file\n",
    "    df = pd.read_json(filepath, lines=True)\n",
    "\n",
    "    # filter by NextVideo action\n",
    "    df = df[(df['page'] == 'NextVideo')]\n",
    "        ## Preprocessing\n",
    "    df['timestamp'] = (df['ts'] -796) / 1000\n",
    "    df['timestamp'] = df['timestamp'].astype(int)\n",
    "    for each in df['timestamp']:\n",
    "#         print(each)\n",
    "        startTime , hr, day, week, month,year, wd = convert_TS_to_date(each)\n",
    "#         print(startTime , hr, day, week, month,year, wd)\n",
    "        cur.execute(Time_table_insert, (startTime , hr, day, week, month,year, wd))\n",
    "    \n",
    "    # convert timestamp column to datetime    \n",
    "    # insert time data records to Time_dim table\n",
    "        # write your code here\n",
    "\n",
    "    #********************************************************************\n",
    "    # load user table\n",
    "    # insert user records into Users_dim table\n",
    "    \n",
    "    for i in df.index:\n",
    "        data = get_UserData(df, i)\n",
    "#         print(data)\n",
    "        cur.execute(Users_table_insert,data)\n",
    "    \n",
    "        # write your code here\n",
    "\n",
    "     #********************************************************************\n",
    "    # insert Videoplay records in Videoplay_fact table\n",
    "#     'auth', 'firstName', 'gender', 'itemInSession', 'lastName', 'length',\n",
    "#        'level', 'location', 'method', 'page', 'registration', 'sessionId',\n",
    "#        'status', 'ts', 'userAgent', 'userId', 'video', 'youtuber']\n",
    "\n",
    "    videoId =0\n",
    "    query = (\"\"\" SELECT v.video_id, y.youtuber_id FROM Videos_dim AS v LEFT OUTER JOIN Youtubers_dim AS y ON y.youtuber_id = v.video_id WHERE v.title =%s AND y.name =%s AND v.duration = %s\"\"\")\n",
    "    \n",
    "#     v_q = \"%sql SELECT * FROM Videoplay_fact WHERE ;\"\n",
    "    for i in df.index:\n",
    "        cur.execute(query, (df.loc[i]['video'],df.loc[i]['youtuber'], df.loc[i]['length']))\n",
    "        missing_data = cur.fetchone()\n",
    "        \n",
    "        if missing_data:\n",
    "            v_id, y_id = missing_data\n",
    "        else:\n",
    "            v_id, y_id = None, None\n",
    "        d = get_startDate(df.loc[i][\"timestamp\"])\n",
    "#         v_id = ''\n",
    "#         y_id =''\n",
    "        v_r = (videoId,d,df.loc[i]['userId'],df.loc[i]['level'],v_id,y_id,df.loc[i]['sessionId'],df.loc[i]['location'],df.loc[i]['userAgent'] )\n",
    "        videoId+=1\n",
    "#         print(v_r)\n",
    "#         cur.execute(\"INSERT INTO Videoplay_fact (videoplay_id, start_time ,user_id , level , video_id ,youtuber_id , session_id , location , user_agent) VALUES (%s,%s, %s,%s,%s, %s,%s,%s,%s)\", v_r)\n",
    "        cur.execute(Videoplay_table_insert, v_r)\n",
    "        # write your code here\n",
    "\n",
    "def get_AllFilesPath(filepath):\n",
    "    fileNames = []\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        files = glob.glob(os.path.join(root, '*.json'))\n",
    "        for name in files:\n",
    "            current = os.path.abspath(name)\n",
    "            fileNames.append(current)\n",
    "    return fileNames\n",
    "\n",
    "def process_data(cur, conn, filepath, func):\n",
    "    \"\"\"\n",
    "        This function get all JSON files in given directory by exploring all sub directories, and process all files that were found using the given function.\n",
    "        Example: if I give it the path to youtube_data directory which resides in data folder of this assignment,\n",
    "        and func given is process_youtubedata_file it should get all JSON files in this directories and process each file using process_youtubedata_file function. \n",
    "        Arguments:\n",
    "        cur: Database Cursor\n",
    "        conn: Database\n",
    "        filepath: location of JSON files\n",
    "        func: function to process all files in the directory\n",
    "        Return: None\n",
    "    \"\"\"\n",
    "    allFiles = get_AllFilesPath(filepath)\n",
    "    if func == process_youtubedata_file:\n",
    "        for currentFile in allFiles:\n",
    "            process_youtubedata_file(cur, currentFile)\n",
    "    elif func == process_log_file:\n",
    "        for currentFile in allFiles:\n",
    "            process_log_file(cur, currentFile)\n",
    "\n",
    "def main():\n",
    "    youtube_data = r'D:\\data\\youtube_data'\n",
    "    log_data = r'D:\\data\\log_data'\n",
    "    conn = psycopg2.connect(\"host=127.0.0.1 dbname=youtubedb user=postgres password=12345678\")\n",
    "    cur = conn.cursor()\n",
    "    conn.set_session(autocommit=True)\n",
    "\n",
    "    process_data(cur, conn, filepath=youtube_data, func=process_youtubedata_file)\n",
    "    process_data(cur, conn, filepath=log_data, func=process_log_file)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
